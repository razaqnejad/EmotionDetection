{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../media/KNTU.png\"  width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection With Machine Learning - Model Training and Real Time Emotion Detection Using KNN, SVM, RF, VggNet, CNN Algorithms\n",
    "##### Algorithmic Graph Theory by Dr. Sheikhi 4022\n",
    "###### Fatemeh Razaqnejad 9822123 - Baran Babaei 9931893 - Alireza DolatAbadi 9821853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Dataset: https://drive.google.com/file/d/1tedoFTFFBbM2iUvdg37WQFSq07ghYrll/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to follow\n",
    "1. Adding Libraries\n",
    "2. Loading dataset\n",
    "3. Apply PCA and save PCA data\n",
    "4. Train with SVM, RF, CNN, VggNet and KNN algorithm and save model data\n",
    "5. Load Model\n",
    "6. Get reports\n",
    "7. Save output of test predicts\n",
    "8. Reload model and map emotions\n",
    "9. Real-Time face recognition\n",
    "10. Real-Time recognition with adding emoji on face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already splited the dataset into test and train in the \"Data Validation\" phase, so we just need to load the images into arrays az input out put. in this part **x** is reffering to image files and **y** is reffering to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (6961, 50176)\n",
      "Shape of y_train: (6961,)\n",
      "Shape of X_test: (1740, 50176)\n",
      "Shape of y_test: (1740,)\n"
     ]
    }
   ],
   "source": [
    "# Function to load images from a folder and flatten them\n",
    "def load_images_from_folder(folder, label, size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    original_images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "        if img is not None:\n",
    "            img_resized = cv2.resize(img, size)  # Resize the image\n",
    "            original_images.append(img_resized)  # Keep original image\n",
    "            images.append(img_resized.flatten())  # Flatten image array and add to list\n",
    "            labels.append(label)  # Assign label based on folder name\n",
    "    return np.array(images), np.array(labels), original_images\n",
    "\n",
    "# Load train images and labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "original_images_train = []\n",
    "\n",
    "for label in range(7):\n",
    "    train_data_folder = f'../data/dataset/train/{label}'\n",
    "    images, labels, original_images = load_images_from_folder(train_data_folder, label)\n",
    "    X_train.extend(images)\n",
    "    y_train.extend(labels)\n",
    "    original_images_train.extend(original_images)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Load test images and labels\n",
    "X_test = []\n",
    "y_test = []\n",
    "original_images_test = []\n",
    "\n",
    "for label in range(7):\n",
    "    test_data_folder = f'../data/dataset/test/{label}'\n",
    "    images, labels, original_images = load_images_from_folder(test_data_folder, label)\n",
    "    X_test.extend(images)\n",
    "    y_test.extend(labels)\n",
    "    original_images_test.extend(original_images)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "# Check if X_train and y_train are correctly populated\n",
    "if len(X_train) == 0 or len(X_test) == 0:\n",
    "    raise ValueError(\"X_train or X_test is empty. Check your data loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load data for VggNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_images_from_folder(folder, label, size=(224, 224)):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     original_images = []\n",
    "#     for filename in os.listdir(folder):\n",
    "#         img_path = os.path.join(folder, filename)\n",
    "#         img = cv2.imread(img_path)  # Load image in color (BGR)\n",
    "#         if img is not None:\n",
    "#             img_resized = cv2.resize(img, size)  # Resize the image\n",
    "#             original_images.append(img_resized)  # Keep original image\n",
    "#             images.append(img_resized)  # Add to list without flattening\n",
    "#             labels.append(label)  # Assign label based on folder name\n",
    "#     return np.array(images), np.array(labels), original_images\n",
    "\n",
    "# # Adjust the rest of the data loading process accordingly\n",
    "# # Load train images and labels\n",
    "# X_train = []\n",
    "# y_train = []\n",
    "# original_images_train = []\n",
    "\n",
    "# for label in range(7):\n",
    "#     train_data_folder = f'../data/dataset/train/{label}'\n",
    "#     images, labels, original_images = load_images_from_folder(train_data_folder, label)\n",
    "#     X_train.extend(images)\n",
    "#     y_train.extend(labels)\n",
    "#     original_images_train.extend(original_images)\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# # Load test images and labels\n",
    "# X_test = []\n",
    "# y_test = []\n",
    "# original_images_test = []\n",
    "\n",
    "# for label in range(7):\n",
    "#     test_data_folder = f'../data/dataset/test/{label}'\n",
    "#     images, labels, original_images = load_images_from_folder(test_data_folder, label)\n",
    "#     X_test.extend(images)\n",
    "#     y_test.extend(labels)\n",
    "#     original_images_test.extend(original_images)\n",
    "\n",
    "# X_test = np.array(X_test)\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# # Normalize the data\n",
    "# X_train = X_train / 255.0\n",
    "# X_test = X_test / 255.0\n",
    "\n",
    "# # Convert labels to categorical one-hot encoding\n",
    "# y_train_categorical = to_categorical(y_train, num_classes=7)\n",
    "# y_test_categorical = to_categorical(y_test, num_classes=7)\n",
    "\n",
    "# # Print shapes for debugging\n",
    "# print(f\"Shape of X_train: {X_train.shape}\")\n",
    "# print(f\"Shape of y_train: {y_train.shape}\")\n",
    "# print(f\"Shape of X_test: {X_test.shape}\")\n",
    "# print(f\"Shape of y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA and Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a statistical technique used for dimensionality reduction. It transforms a large set of variables into a smaller one that still contains most of the information in the large set. PCA works by identifying the directions (principal components) along which the variance of the data is maximized. By projecting the data onto these principal components, we can reduce the number of features while preserving as much variability as possible. This is particularly useful in machine learning to enhance computational efficiency and reduce the risk of overfitting, especially when dealing with high-dimensional data.\n",
    "\n",
    "In this section of the project, we first standardized the data using StandardScaler. Standardization is a crucial step in PCA as it ensures that each feature contributes equally to the result. Without standardization, features with larger ranges would dominate the principal components, skewing the results. We applied the fit_transform method on the training data and the transform method on the test data to ensure consistent scaling.\n",
    "\n",
    "Next, we applied PCA to reduce the dimensionality of our dataset. We chose to keep 100 principal components, a number that balances between retaining variance and reducing complexity. The explained variance ratio was computed to understand how much information each principal component captures. By plotting the cumulative explained variance, we visualized the proportion of the dataset's variance captured as we include more principal components. Finally, we saved the fitted scaler and PCA models using joblib, ensuring that our data preprocessing steps could be consistently applied during model training and future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.27403079 0.12019909 0.09316748 0.04646483 0.03506966 0.02675164\n",
      " 0.02230124 0.01689225 0.01561983 0.01328226 0.01307359 0.01126549\n",
      " 0.0098579  0.00964006 0.00870928 0.00824669 0.00655508 0.00619306\n",
      " 0.00588233 0.00551681 0.00547474 0.00521007 0.00507774 0.00494885\n",
      " 0.0046348  0.00454777 0.00435411 0.00407263 0.00383569 0.00374333\n",
      " 0.00352009 0.00329079 0.00295911 0.00290139 0.00282498 0.00274852\n",
      " 0.00268985 0.00265056 0.00260657 0.00244609 0.00239811 0.00233792\n",
      " 0.00223745 0.00218103 0.00216574 0.00213408 0.00210489 0.00201707\n",
      " 0.00187595 0.00185702 0.00180846 0.00179303 0.00173922 0.0016808\n",
      " 0.00162788 0.00158003 0.00156786 0.00154824 0.00152359 0.00148544\n",
      " 0.00143356 0.0014021  0.00138181 0.00136175 0.00133193 0.00128856\n",
      " 0.00124653 0.00123872 0.00121727 0.00119206 0.00117721 0.00116239\n",
      " 0.00114791 0.0011198  0.00110514 0.00107607 0.00105335 0.00102992\n",
      " 0.00101335 0.00099982 0.00098192 0.000972   0.0009424  0.00093511\n",
      " 0.00090955 0.00090806 0.00088623 0.00087667 0.00086682 0.00084792\n",
      " 0.000835   0.00082336 0.0008037  0.00080046 0.00077901 0.00076908\n",
      " 0.00074979 0.00074593 0.00072833 0.00070687]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to scaler.pkl\n",
      "PCA saved to pca.pkl\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the number of principal components to keep\n",
    "n_components = 100  # You can adjust this number based on your dataset and computational resources\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratio: {explained_variance_ratio}\")\n",
    "\n",
    "# Optionally, you can plot the explained variance to decide on the number of components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(explained_variance_ratio))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save the scaler and PCA models to files\n",
    "scaler_filename = 'scaler.pkl'\n",
    "pca_filename = 'pca.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "joblib.dump(pca, pca_filename)\n",
    "print(f\"Scaler saved to {scaler_filename}\")\n",
    "print(f\"PCA saved to {pca_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply PCA for VggNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the batch size\n",
    "# batch_size = 100  # Reduce batch size to decrease memory usage\n",
    "\n",
    "# # Initialize the scaler and PCA\n",
    "# scaler = StandardScaler()\n",
    "# pca = IncrementalPCA(n_components=100)  # Adjust n_components based on your needs\n",
    "\n",
    "# # Process the data in batches\n",
    "# def process_in_batches(data, transformer, batch_size, fit=True):\n",
    "#     result = []\n",
    "#     for i in range(0, data.shape[0], batch_size):\n",
    "#         batch = data[i:i + batch_size]\n",
    "#         if fit:\n",
    "#             transformer.partial_fit(batch)\n",
    "#         transformed_batch = transformer.transform(batch)\n",
    "#         result.append(transformed_batch)\n",
    "#     return np.vstack(result)\n",
    "\n",
    "# # Fit the scaler and PCA incrementally\n",
    "# for i in range(0, X_train.shape[0], batch_size):\n",
    "#     scaler.partial_fit(X_train[i:i + batch_size])\n",
    "# for i in range(0, X_train.shape[0], batch_size):\n",
    "#     pca.partial_fit(scaler.transform(X_train[i:i + batch_size]))\n",
    "\n",
    "# # Transform the data incrementally\n",
    "# X_train_scaled = np.vstack([scaler.transform(X_train[i:i + batch_size]) for i in range(0, X_train.shape[0], batch_size)])\n",
    "# X_train_pca = np.vstack([pca.transform(X_train_scaled[i:i + batch_size]) for i in range(0, X_train_scaled.shape[0], batch_size)])\n",
    "# X_test_scaled = np.vstack([scaler.transform(X_test[i:i + batch_size]) for i in range(0, X_test.shape[0], batch_size)])\n",
    "# X_test_pca = np.vstack([pca.transform(X_test_scaled[i:i + batch_size]) for i in range(0, X_test_scaled.shape[0], batch_size)])\n",
    "\n",
    "# # Explained variance ratio\n",
    "# explained_variance_ratio = pca.explained_variance_ratio_\n",
    "# print(f\"Explained variance ratio: {explained_variance_ratio}\")\n",
    "\n",
    "# # Optionally, you can plot the explained variance to decide on the number of components\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(np.cumsum(explained_variance_ratio))\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.title('Explained Variance by PCA Components')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Save the scaler and PCA models to files\n",
    "# scaler_filename = 'scaler.pkl'\n",
    "# pca_filename = 'pca.pkl'\n",
    "# joblib.dump(scaler, scaler_filename)\n",
    "# joblib.dump(pca, pca_filename)\n",
    "# print(f\"Scaler saved to {scaler_filename}\")\n",
    "# print(f\"PCA saved to {pca_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why We Chose Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained three different models to compare their performance:\n",
    "\n",
    "1. **Random Forest**: A robust ensemble method that combines multiple decision trees to improve classification accuracy.\n",
    "2. **KNN (K-Nearest Neighbors)**: A simple, instance-based learning algorithm that classifies data points based on their distance to the nearest training examples.\n",
    "3. **CNN (Convolutional Neural Network)**: A deep learning model particularly well-suited for image data, as it can capture spatial hierarchies through convolutional layers.\n",
    "\n",
    "Based on the evaluation metrics, we decided to use the Random Forest model for further analysis. The reasons for this decision include:\n",
    "\n",
    "1. **Robustness**: Random Forest is less likely to overfit compared to individual decision trees.\n",
    "2. **Accuracy**: As shown in the evaluation results, the Random Forest model achieved a significantly higher accuracy and F1-score compared to KNN and CNN.\n",
    "3. **Interpretability**: Random Forest models provide insights into feature importance, which can be valuable for understanding the model's decision-making process.\n",
    "\n",
    "The Random Forest model outperformed the other models in terms of precision, recall, and F1-score across most emotion classes, making it the most suitable choice for our emotion detection task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: flex-start;\">\n",
    "    <div style=\"margin-right: 20px;\">\n",
    "        <strong>Random Forest</strong>\n",
    "        <br>\n",
    "        <img src=\"../media/RF_report.png\" width=\"350\">\n",
    "    </div>\n",
    "    <div style=\"margin-right: 20px;\">\n",
    "        <strong>KNN</strong>\n",
    "        <br>\n",
    "        <img src=\"../media/KNN_report.png\" width=\"350\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <strong>CNN</strong>\n",
    "        <br>\n",
    "        <img src=\"../media/CNN_report.png\" width=\"350\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we train a Random Forest model for emotion detection using facial images. The following steps outline the process of training, predicting, and evaluating the Random Forest model.\n",
    "The Random Forest model is chosen for its robustness and high performance in our classification task, as indicated by its superior evaluation metrics compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to RF_trained_model.pkl\n",
      "Accuracy: 0.5005747126436781\n",
      "Confusion Matrix:\n",
      " [[ 41   0   4 130   1   0  57]\n",
      " [  0  13   0  15   0   1   4]\n",
      " [  5   0  41  95   2  11  36]\n",
      " [  3   0   2 492   1   3  34]\n",
      " [  7   0   3  97  16   3  60]\n",
      " [  0   0   3  54   0  98  25]\n",
      " [  5   0   2 199   4   3 170]]\n"
     ]
    }
   ],
   "source": [
    "#### Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate performance using various metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Save the trained model to a file\n",
    "model_filename = 'RF_trained_model.pkl'\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# Display results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Algorithms (backup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VggNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_vgg_model(input_shape=(224, 224, 3), num_classes=7):\n",
    "#     model = Sequential([\n",
    "#         Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "#         Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#         MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "#         Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "#         Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "#         MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "#         Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#         Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#         Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#         MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "#         Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#         Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#         Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#         MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "#         Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#         Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#         Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#         MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "#         Flatten(),\n",
    "#         Dense(4096, activation='relu'),\n",
    "#         Dense(4096, activation='relu'),\n",
    "#         Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Build the model\n",
    "# model = build_vgg_model()\n",
    "# model.summary()\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train_categorical, epochs=10, batch_size=64, validation_data=(X_test, y_test_categorical))\n",
    "\n",
    "# # Evaluate the model\n",
    "# score = model.evaluate(X_test, y_test_categorical, verbose=0)\n",
    "# print(f\"Test loss: {score[0]}\")\n",
    "# print(f\"Test accuracy: {score[1]}\")\n",
    "\n",
    "# # Save the model\n",
    "# model.save('vgg_emotion_detection_model.h5')\n",
    "# print(\"VGGNet model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the parameter grid for SVM\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'gamma': [1, 0.1, 0.01, 0.001],\n",
    "#     'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "\n",
    "# # Initialize Grid Search with cross-validation\n",
    "# grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
    "\n",
    "# # Fit Grid Search to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and best estimator\n",
    "# best_params = grid_search.best_params_\n",
    "# best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# print(f\"Best Parameters: {best_params}\")\n",
    "# print(f\"Best Estimator: {best_estimator}\")\n",
    "\n",
    "# # Predict with the best estimator\n",
    "# y_pred_svm = best_estimator.predict(X_test)\n",
    "\n",
    "# # Evaluate performance using various metrics for the best estimator\n",
    "# accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "# conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# # Save the trained SVM model to a file\n",
    "# svm_model_filename = 'svm_trained_model.pkl'\n",
    "# joblib.dump(best_estimator, svm_model_filename)\n",
    "# print(f\"SVM Model saved to {svm_model_filename}\")\n",
    "\n",
    "# # Display results for the best estimator\n",
    "# print(f'SVM Accuracy: {accuracy_svm}')\n",
    "# print(f'SVM Confusion Matrix:\\n {conf_matrix_svm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model saved to KNN_trained_model.pkl\n",
      "KNN Accuracy: 0.39482758620689656\n",
      "KNN Confusion Matrix:\n",
      " [[ 65   7  21  67  11   8  54]\n",
      " [  3  14   3   4   4   1   4]\n",
      " [ 21   4  55  46   7  18  39]\n",
      " [ 46  10  27 301  23  15 113]\n",
      " [ 27   6  15  56  24   5  53]\n",
      " [ 11   5  25  53   6  61  19]\n",
      " [ 38   5  27 116  20  10 167]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train KNN Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data using KNN\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance using various metrics for KNN\n",
    "accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Save the trained KNN model to a file\n",
    "knn_model_filename = 'KNN_trained_model.pkl'\n",
    "joblib.dump(knn_model, knn_model_filename)\n",
    "print(f\"KNN Model saved to {knn_model_filename}\")\n",
    "\n",
    "# Display results for KNN\n",
    "print(f'KNN Accuracy: {accuracy_knn}')\n",
    "print(f'KNN Confusion Matrix:\\n {conf_matrix_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: 224x224\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 337s 3s/step - loss: 2.1950 - accuracy: 0.3139 - val_loss: 1.6145 - val_accuracy: 0.3908\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 383s 4s/step - loss: 1.4563 - accuracy: 0.4656 - val_loss: 1.4465 - val_accuracy: 0.4638\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 395s 4s/step - loss: 1.1617 - accuracy: 0.5730 - val_loss: 1.4125 - val_accuracy: 0.4862\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 394s 4s/step - loss: 0.8672 - accuracy: 0.6982 - val_loss: 1.4734 - val_accuracy: 0.5098\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 430s 4s/step - loss: 0.5704 - accuracy: 0.8102 - val_loss: 1.6969 - val_accuracy: 0.5103\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 424s 4s/step - loss: 0.3510 - accuracy: 0.8924 - val_loss: 1.9298 - val_accuracy: 0.5207\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 433s 4s/step - loss: 0.1938 - accuracy: 0.9496 - val_loss: 2.2145 - val_accuracy: 0.5063\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 447s 4s/step - loss: 0.1025 - accuracy: 0.9805 - val_loss: 2.5987 - val_accuracy: 0.5184\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 437s 4s/step - loss: 0.0727 - accuracy: 0.9899 - val_loss: 2.7031 - val_accuracy: 0.5207\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 387s 4s/step - loss: 0.0680 - accuracy: 0.9905 - val_loss: 2.7669 - val_accuracy: 0.5132\n",
      "Test loss: 2.766944408416748\n",
      "Test accuracy: 0.5132184028625488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\razaq\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model saved to cnn_trained_model.h5\n",
      "Scaler saved to scaler.pkl\n",
      "PCA saved to pca.pkl\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of a single image\n",
    "image_shape = int(np.sqrt(X_train.shape[1]))\n",
    "print(f\"Image shape: {image_shape}x{image_shape}\")\n",
    "\n",
    "# Reshape the data to fit the model\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], image_shape, image_shape, 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], image_shape, image_shape, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_train_reshaped = X_train_reshaped / 255.0\n",
    "X_test_reshaped = X_test_reshaped / 255.0\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train_categorical = to_categorical(y_train, num_classes=7)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=7)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_shape, image_shape, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(224, activation='relu'),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train_categorical, validation_data=(X_test_reshaped, y_test_categorical), epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test_reshaped, y_test_categorical, verbose=0)\n",
    "print(f\"Test loss: {score[0]}\")\n",
    "print(f\"Test accuracy: {score[1]}\")\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'cnn_trained_model.h5'\n",
    "model.save(model_filename)\n",
    "print(f\"CNN Model saved to {model_filename}\")\n",
    "\n",
    "# Save the scaler and PCA models to files for consistency\n",
    "scaler_filename = 'scaler.pkl'\n",
    "pca_filename = 'pca.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "joblib.dump(pca, pca_filename)\n",
    "print(f\"Scaler saved to {scaler_filename}\")\n",
    "print(f\"PCA saved to {pca_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from cnn_trained_model.h5\n",
      "55/55 [==============================] - 20s 358ms/step\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[ 93   1  16  38  28  15  42]\n",
      " [  2  14   3   4   2   2   6]\n",
      " [ 24   0  71  30  15  22  28]\n",
      " [ 45   0  27 350  28  21  64]\n",
      " [ 33   0  29  18  55  12  39]\n",
      " [  9   0  18   9   8 116  20]\n",
      " [ 51   0  30  70  44  17 171]]\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model from the file\n",
    "model_filename = 'cnn_trained_model.h5'\n",
    "model = load_model(model_filename)\n",
    "print(f\"Model loaded from {model_filename}\")\n",
    "\n",
    "# Use the loaded model for predictions\n",
    "X_test_reshaped = np.reshape(X_test, (-1, 224, 224, 1))\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "# Evaluate performance using various metrics\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Display results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we evaluate the performance of our trained Random Forest model on the test data. We use several metrics to provide a comprehensive understanding of the model's effectiveness in classifying emotions. Here are the steps and explanations of the code used to generate the performance report:\n",
    "The provided report shows the precision, recall, and F1-score for each class (0-6, representing different emotions) along with the overall accuracy, macro average, and weighted average. The Random Forest model's performance metrics indicate its ability to correctly classify emotions, and the weighted F1 score provides an overall performance measure.\n",
    "\n",
    "   - **Precision**: The ratio of correctly predicted positive observations to the total predicted positives. It indicates how many selected items are relevant.\n",
    "   - **Recall**: The ratio of correctly predicted positive observations to all observations in the actual class. It indicates how many relevant items are selected.\n",
    "   - **F1-score**: The weighted average of precision and recall. It provides a balance between precision and recall.\n",
    "   - **Support**: The number of actual occurrences of the class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.40      0.38       233\n",
      "           1       0.93      0.42      0.58        33\n",
      "           2       0.37      0.37      0.37       190\n",
      "           3       0.67      0.65      0.66       535\n",
      "           4       0.31      0.30      0.30       186\n",
      "           5       0.57      0.64      0.60       180\n",
      "           6       0.46      0.45      0.45       383\n",
      "\n",
      "    accuracy                           0.50      1740\n",
      "   macro avg       0.52      0.46      0.48      1740\n",
      "weighted avg       0.51      0.50      0.50      1740\n",
      "\n",
      "Weighted F1 Score: 0.5009136612941564\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, F1-score, and support\n",
    "report = classification_report(y_test, y_pred_classes)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Calculate F1-score directly\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "print(f'Weighted F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Output of Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we save the predictions of our model on the test dataset. This process involves detecting faces in the test images, predicting the emotion, and saving the images with bounding boxes and labels indicating the detected emotion. Here's a brief explanation of what we did:\n",
    "\n",
    "   - For each test image, we detect faces using the Haarcascade model.\n",
    "   - For each detected face, we draw a bounding box around the face.\n",
    "   - We predict the emotion of the face using our trained model.\n",
    "   - We add a text label indicating the predicted emotion on the image.\n",
    "   - The processed image is then saved in the output directory with the bounding box and emotion label.\n",
    "\n",
    "By saving the processed test images with bounding boxes and emotion labels, we can visually inspect and verify the predictions made by our model. This step is crucial for evaluating the performance of our model in a real-world scenario, providing clear insights into how well the model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in directory: ../output/test_images\n"
     ]
    }
   ],
   "source": [
    "# Mapping of classes\n",
    "class_mapping = {\n",
    "    '0': 'Angry',\n",
    "    '1': 'Disgust',\n",
    "    '2': 'Fear',\n",
    "    '3': 'Happy',\n",
    "    '4': 'Sad',\n",
    "    '5': 'Surprise',\n",
    "    '6': 'Neutral'\n",
    "}\n",
    "\n",
    "# Load Haarcascade model for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "if face_cascade.empty():\n",
    "    raise IOError(\"Haarcascade file not found or failed to load\")\n",
    "\n",
    "# Save predicted results with bounding boxes and class labels\n",
    "output_folder = '../output/test_images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for i, (image, original_image) in enumerate(zip(X_test, original_images_train)):\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(original_image, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(original_image, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "\n",
    "        # Add text label on top of the bounding box\n",
    "        class_label = class_mapping[str(y_pred[i])]\n",
    "        cv2.putText(original_image, class_label, (x, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "    # Save the image with bounding box and label\n",
    "    output_path = os.path.join(output_folder, f'image_{i}_{class_mapping[str(y_pred[i])]}.png')\n",
    "    cv2.imwrite(output_path, original_image)\n",
    "\n",
    "print(\"Results saved in directory:\", output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we load the previously saved model, scaler, and PCA components from their respective files to use them for real-time emotion detection.\n",
    "By reloading the trained model, scaler, and PCA components, we can ensure that our real-time emotion detection system uses the same settings and transformations that were used during training, maintaining consistency and accuracy in predictions. This setup is essential for running the real-time face detection and emotion recognition with emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from cnn_trained_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model_filename = 'cnn_trained_model.h5'\n",
    "model = load_model(model_filename)\n",
    "print(f\"Model loaded from {model_filename}\")\n",
    "\n",
    "# Mapping of emotions to emojis\n",
    "class_mapping = {\n",
    "    '0': 'Angry',\n",
    "    '1': 'Disgust',\n",
    "    '2': 'Fear',\n",
    "    '3': 'Happy',\n",
    "    '4': 'Sad',\n",
    "    '5': 'Surprise',\n",
    "    '6': 'Neutral'\n",
    "}\n",
    "\n",
    "# Load emoji images with alpha channel\n",
    "emoji_mapping = {str(i): cv2.imread(f'../media/emojis/{i}.png', cv2.IMREAD_UNCHANGED) for i in range(7)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload model for VggNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the trained model from the file\n",
    "# from keras.models import load_model\n",
    "\n",
    "\n",
    "# # Use the loaded model for predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# scaler_filename = 'scaler.pkl'\n",
    "# pca_filename = 'pca.pkl'\n",
    "\n",
    "# model = load_model('vgg_emotion_detection_model.h5')\n",
    "# scaler = joblib.load(scaler_filename)\n",
    "# pca = joblib.load(pca_filename)\n",
    "\n",
    "# print(f\"Model loaded from vgg_emotion_detection_model.h5\")\n",
    "# print(f\"Scaler and PCA loaded from {scaler_filename} and {pca_filename}\")\n",
    "\n",
    "# # Mapping of emotions to emojis\n",
    "# class_mapping = {\n",
    "#     '0': 'Angry',\n",
    "#     '1': 'Disgust',\n",
    "#     '2': 'Fear',\n",
    "#     '3': 'Happy',\n",
    "#     '4': 'Sad',\n",
    "#     '5': 'Surprise',\n",
    "#     '6': 'Neutral'\n",
    "# }\n",
    "\n",
    "# # Load emoji images with alpha channel\n",
    "# emoji_mapping = {str(i): cv2.imread(f'../media/emojis/{i}.png', cv2.IMREAD_UNCHANGED) for i in range(7)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Time Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we implemented real-time face detection using the Haar Cascade classifier from OpenCV.\n",
    "This setup allows for real-time face detection using the webcam, providing a foundation for more advanced real-time applications like emotion recognition or face tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Realtime face detection using Haar Cascade\n",
    "# def realtime_face_detection():\n",
    "#     face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#     if face_cascade.empty():\n",
    "#         raise IOError(\"Haarcascade file not found or failed to load\")\n",
    "    \n",
    "#     cap = cv2.VideoCapture(0)  # Open the default camera\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()  # Capture frame-by-frame\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=7)\n",
    "\n",
    "#         for (x, y, w, h) in faces:\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "#         cv2.imshow('Realtime Face Detection', frame)\n",
    "\n",
    "#         # Exit the loop when 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Run realtime face detection\n",
    "# realtime_face_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Time Recognition With Emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we implemented a real-time emotion recognition system that overlays emojis on detected faces based on the predicted emotion. Here’s a detailed explanation of the process:\n",
    "\n",
    "1. **Resizing the Emoji Image**:\n",
    "    - The emoji image is resized to fit the detected face region using `cv2.resize()`. This ensures the emoji aligns properly with the face's dimensions.\n",
    "\n",
    "2. **Separating the Color Channels and Alpha Channel**:\n",
    "    - If the emoji image has an alpha channel (indicating transparency), we separate the RGB color channels and the alpha channel. If not, we create a default alpha channel filled with ones, meaning no transparency.\n",
    "\n",
    "3. **Creating Masks**:\n",
    "    - A binary mask and its inverse are created from the alpha channel using `cv2.threshold()` and `cv2.bitwise_not()`. The binary mask helps in identifying the non-transparent regions of the emoji.\n",
    "\n",
    "4. **Region of Interest (ROI)**:\n",
    "    - We define the region of interest (ROI) in the original image where the emoji will be placed. This is done by selecting the region corresponding to the detected face.\n",
    "\n",
    "5. **Applying the Mask to the ROI**:\n",
    "    - We use the inverse mask to black out the area of the emoji in the ROI. This ensures that the emoji does not overlay existing features of the face.\n",
    "    - The original image background and the emoji foreground are combined using `cv2.bitwise_and()`, ensuring that only the emoji is placed over the face without altering the surrounding pixels.\n",
    "\n",
    "6. **Combining Emoji with the Original Image**:\n",
    "    - The processed emoji is combined with the original image's ROI, resulting in the emoji being overlaid on the face. The final combined image is then updated in the original frame.\n",
    "\n",
    "By using masks and separating color channels, we ensure that the emojis are correctly overlaid on the faces without disrupting the background or other parts of the image, creating a seamless integration of emojis with the detected faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see some saples of outputs down below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: flex-start;\">\n",
    "    <div style=\"margin-right: 20px;\">\n",
    "        <div>\n",
    "            <strong>Angry</strong>\n",
    "            <br>\n",
    "            <img src=\"../media/Real_Time/angry.png\" width=\"350\" style=\"margin-top: 10px;\">\n",
    "        </div>\n",
    "        <div style=\"margin-top: 10px;\">\n",
    "            <strong>Happy</strong>\n",
    "            <br>\n",
    "            <img src=\"../media/Real_Time/happy.png\" width=\"350\" style=\"margin-top: 10px;\">\n",
    "        </div>\n",
    "    </div>\n",
    "    <div style=\"margin-right: 20px;\">\n",
    "        <div>\n",
    "            <strong>Surprise</strong>\n",
    "            <br>\n",
    "            <img src=\"../media/Real_Time/surprise.png\" width=\"350\" style=\"margin-top: 10px;\">\n",
    "        </div>\n",
    "        <div style=\"margin-top: 10px;\">\n",
    "            <strong>Sad</strong>\n",
    "            <br>\n",
    "            <img src=\"../media/Real_Time/sad.png\" width=\"350\" style=\"margin-top: 10px;\">\n",
    "        </div>\n",
    "    </div>\n",
    "    <div style=\"margin-right: 20px;\">\n",
    "        <div>\n",
    "            <strong>Fear</strong>\n",
    "            <br>\n",
    "            <img src=\"../media/Real_Time/fear.png\" width=\"350\" style=\"margin-top: 10px;\">\n",
    "        </div>\n",
    "        <div style=\"margin-top: 10px;\">\n",
    "            <strong>Neutral</strong>\n",
    "            <br>\n",
    "            <img src=\"../media/Real_Time/neutral.png\" width=\"350\" style=\"margin-top: 10px;\">\n",
    "        </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 800ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "def add_emoji_to_image(image, emoji_img, x, y, w, h):\n",
    "    # Resize emoji to fit the face region\n",
    "    emoji_resized = cv2.resize(emoji_img, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Separate the color channels and the alpha channel\n",
    "    if emoji_resized.shape[2] == 4:\n",
    "        emoji_rgb = emoji_resized[:, :, :3]\n",
    "        emoji_alpha = emoji_resized[:, :, 3]\n",
    "    else:\n",
    "        emoji_rgb = emoji_resized\n",
    "        emoji_alpha = np.ones(emoji_rgb.shape[:2], dtype=emoji_rgb.dtype) * 255\n",
    "\n",
    "    # Create a mask of the emoji and its inverse mask\n",
    "    _, mask = cv2.threshold(emoji_alpha, 1, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Take ROI for emoji in the image\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Now black-out the area of emoji in ROI\n",
    "    img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "    # Take only region of emoji from emoji image\n",
    "    emoji_fg = cv2.bitwise_and(emoji_rgb, emoji_rgb, mask=mask)\n",
    "\n",
    "    # Put emoji in ROI and modify the main image\n",
    "    dst = cv2.add(img_bg, emoji_fg)\n",
    "    image[y:y+h, x:x+w] = dst\n",
    "\n",
    "def preprocess_image(image):\n",
    "    img_resized = cv2.resize(image, (224, 224))  # Resize image to 224x224\n",
    "    img_grayscale = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    img_normalized = img_grayscale / 255.0  # Normalize the image\n",
    "    img_expanded = np.expand_dims(img_normalized, axis=-1)  # Add channel dimension\n",
    "    return np.expand_dims(img_expanded, axis=0)  # Add batch dimension\n",
    "\n",
    "def realtime_face_detection_with_emoji():\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    if face_cascade.empty():\n",
    "        raise IOError(\"Haarcascade file not found or failed to load\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)  # Open the default camera\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Capture frame-by-frame\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "        cv2.imshow('Realtime Face', frame)\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = frame[y:y+h, x:x+w]  # Use color image for CNN model\n",
    "            face_preprocessed = preprocess_image(face_img)\n",
    "            y_pred = model.predict(face_preprocessed)\n",
    "            y_pred_class = np.argmax(y_pred, axis=1)[0]\n",
    "            emoji_img = emoji_mapping[str(y_pred_class)]\n",
    "            add_emoji_to_image(frame, emoji_img, x, y, w, h)\n",
    "\n",
    "            # Draw a rectangle around the face and add text label\n",
    "            class_label = class_mapping[str(y_pred_class)]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, class_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Realtime Face Detection with Emoji', frame)\n",
    "\n",
    "        # Exit the loop when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run realtime face detection with emoji\n",
    "realtime_face_detection_with_emoji()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Time Emoji Simulation With VggNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_emoji_to_image(image, emoji_img, x, y, w, h):\n",
    "#     # Resize emoji to fit the face region\n",
    "#     emoji_resized = cv2.resize(emoji_img, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#     # Separate the color channels and the alpha channel\n",
    "#     if emoji_resized.shape[2] == 4:\n",
    "#         emoji_rgb = emoji_resized[:, :, :3]\n",
    "#         emoji_alpha = emoji_resized[:, :, 3]\n",
    "#     else:\n",
    "#         emoji_rgb = emoji_resized\n",
    "#         emoji_alpha = np.ones(emoji_rgb.shape[:2], dtype=emoji_rgb.dtype) * 255\n",
    "\n",
    "#     # Create a mask of the emoji and its inverse mask\n",
    "#     _, mask = cv2.threshold(emoji_alpha, 1, 255, cv2.THRESH_BINARY)\n",
    "#     mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "#     # Take ROI for emoji in the image\n",
    "#     roi = image[y:y+h, x:x+w]\n",
    "\n",
    "#     # Now black-out the area of emoji in ROI\n",
    "#     img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "#     # Take only region of emoji from emoji image\n",
    "#     emoji_fg = cv2.bitwise_and(emoji_rgb, emoji_rgb, mask=mask)\n",
    "\n",
    "#     # Put emoji in ROI and modify the main image\n",
    "#     dst = cv2.add(img_bg, emoji_fg)\n",
    "#     image[y:y+h, x:x+w] = dst\n",
    "\n",
    "\n",
    "\n",
    "# def preprocess_image_vgg(image):\n",
    "#     img_resized = cv2.resize(image, (224, 224))  # Resize image to 224x224\n",
    "#     img_normalized = img_resized / 255.0  # Normalize the image\n",
    "#     return np.expand_dims(img_normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# def realtime_face_detection_with_emoji():\n",
    "#     face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#     if face_cascade.empty():\n",
    "#         raise IOError(\"Haarcascade file not found or failed to load\")\n",
    "    \n",
    "#     cap = cv2.VideoCapture(0)  # Open the default camera\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()  # Capture frame-by-frame\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=6)\n",
    "        \n",
    "#         for (x, y, w, h) in faces:\n",
    "#             face_img = frame[y:y+h, x:x+w]  # Use color image for VGGNet\n",
    "#             face_preprocessed = preprocess_image_vgg(face_img)\n",
    "#             y_pred = model.predict(face_preprocessed)\n",
    "#             y_pred_class = np.argmax(y_pred, axis=1)[0]\n",
    "#             class_label = class_mapping[str(y_pred_class)]\n",
    "#             emoji_img = emoji_mapping[str(y_pred_class)]\n",
    "            \n",
    "#             add_emoji_to_image(frame, emoji_img, x, y, w, h)\n",
    "\n",
    "#             # Draw a rectangle around the face and add text label\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "#             cv2.putText(frame, class_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "#         cv2.imshow('Realtime Face Detection with Emoji', frame)\n",
    "\n",
    "#         # Exit the loop when 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Run realtime face detection with emoji\n",
    "# realtime_face_detection_with_emoji()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
